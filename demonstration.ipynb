{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263f12b-a971-404b-8fc4-ae3705962ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The goal of this file is:\n",
    "    1. To present all the components of the capstone project\n",
    "    2. To be able to load only the trained weights and the video to do so\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c005d76f-0c0e-466c-bf81-5049f69b52bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O: Import Block\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "import csv\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from PIL import Image\n",
    "from openlocationcode import openlocationcode as olc\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy import distance\n",
    "from ipyleaflet import Map, Marker, AntPath\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b99b71-832f-4c56-a89a-acc94ea9f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Parameters\n",
    "# TODO: standardize variable names\n",
    "\n",
    "# https://maps.google.com/pluscodes/support/#why-are-plus-codes-not-sequential-or-incremental\n",
    "VALID_LABELS = [\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "    \"7\",\n",
    "    \"8\",\n",
    "    \"9\",\n",
    "    \"C\",\n",
    "    \"F\",\n",
    "    \"G\",\n",
    "    \"H\",\n",
    "    \"J\",\n",
    "    \"M\",\n",
    "    \"P\",\n",
    "    \"Q\",\n",
    "    \"R\",\n",
    "    \"V\",\n",
    "    \"W\",\n",
    "    \"X\",\n",
    "    \"NULL\",\n",
    "    \"+\",\n",
    "]\n",
    "\n",
    "FILENAME = \"./ocr/SAM_FLIGHT_COMP.mp4\"\n",
    "MODELNAME = 'saved_model/Submission_ML_Model'\n",
    "VIDEO_FPS = 60\n",
    "NUM_CHARS = 12 # The number of characters in a Plus Code. \n",
    "\n",
    "CHARACTER_WIDTH_WITH_SPACE = 23.5\n",
    "CHARACTER_WIDTH = 17\n",
    "# The location in the video where the plus code appears\n",
    "LEFT_START = 211\n",
    "TOP = 455\n",
    "BOTTOM = 482\n",
    "CHARACTER_HEIGHT = BOTTOM - TOP\n",
    "\n",
    "# ML Tunables\n",
    "BATCH_SIZE = 12\n",
    "VALIDATION_RATIO = 0.3\n",
    "EPOCHS = 15\n",
    "MODEL_NAME = \"ImpactOCR\"\n",
    "WORKER_COUNT = 8\n",
    "\n",
    "# Data validation tunables\n",
    "MAX_REASONABLE_METERS_SEC = 70\n",
    "MIN_REASONABLE_METERS_SEC = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1bf9109-30d1-410b-b7d9-4ba8d7c4f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Helper Block\n",
    "\n",
    "def distance_meters(a_coordinates, b_coordinates):\n",
    "    a = (a_coordinates[0], a_coordinates[1])\n",
    "    b = (b_coordinates[0], b_coordinates[1])\n",
    "    return distance.distance(a, b).meters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0dd37144-e68b-4c7a-b0c8-e951ce6b6506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5243eec4757841658b0fa680e5a04f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntRangeSlider(value=(17, 70), description='Speed Range:', step=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3: Interactive Component\n",
    "# Since the model predicts what codes are valid, and what are not based off of the top and bottom speeds, \n",
    "# there is a chance that different aircraft will be interpreted differently by the model. \n",
    "# This section allows the user to tune the predictive component based off of the reasonable expected speeds between the top-end and the bottom end.\n",
    "\n",
    "a = MIN_REASONABLE_METERS_SEC\n",
    "b = MAX_REASONABLE_METERS_SEC\n",
    "\n",
    "testvar = 0\n",
    "\n",
    "acceptable_speed_range = widgets.IntRangeSlider(\n",
    "    value=[a,b],\n",
    "    min=0., max=200., step=0.1,\n",
    "    \n",
    "    description='Speed Range:',\n",
    "    continuous_update = True,\n",
    "    readout_format='d',\n",
    ")\n",
    "\n",
    "def on_value_change(change):\n",
    "    global MIN_REASONABLE_METERS_SEC\n",
    "    global MAX_REASONABLE_METERS_SEC\n",
    "    MIN_REASONABLE_METERS_SEC = change['new'][0]\n",
    "    MAX_REASONABLE_METERS_SEC = change['new'][1]\n",
    "\n",
    "\n",
    "display(acceptable_speed_range)\n",
    "acceptable_speed_range.observe(on_value_change, names='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71aa3d5a-ac44-4cdb-bb83-6adf59dd474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 27, 17, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 27, 17, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 8, 8)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 8, 16)         1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 4, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 4, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 22)                1430      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,670\n",
      "Trainable params: 19,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 4: Data Load Block\n",
    "\n",
    "# Takes a pre-trained model, and loads it into memory. The model was trained using characters algorithmically extracted from the same video that is being analyzed.\n",
    "\n",
    "submission_model = tf.keras.models.load_model(MODELNAME)\n",
    "submission_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914d5ca-242f-415d-9a7b-8d4da04893df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b39b762ce3840269bbbeb252aca58a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed:   0%|          | 0/1270 [00:00<?, ? seconds/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5: Descriptive Data Generation/Non-Descriptive Component\n",
    "\n",
    "# Descriptive Component: Watches the video, interprets characters, translates into latitude/longitude, and calculates average/max speed based on distance between pins.\n",
    "\n",
    "\n",
    "# This is where the video is transformed into a manipulable object from it's source.\n",
    "capture = cv2.VideoCapture(FILENAME)\n",
    "length_seconds = capture.get(cv2.CAP_PROP_FRAME_COUNT) / VIDEO_FPS\n",
    "\n",
    "n = 0 # Number of frames polled\n",
    "found_coordinates = []\n",
    "invalid_coordinates = []\n",
    "last_successful_frame_number = 0\n",
    "\n",
    "total_distance = 0\n",
    "greatest_speed = 0\n",
    "least_speed = 100\n",
    "\n",
    "pbar = tqdm(total=int(length_seconds), desc=\"Processed\", unit=\" seconds\", position=0)\n",
    "while True:\n",
    "    # Capture frames until there are no more frames in the video.\n",
    "    success, frame = capture.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Convert from RGB to grayscale\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    n = n + 1\n",
    "    # Only pull a frame per second\n",
    "    if n % VIDEO_FPS != 0:\n",
    "        continue\n",
    "    frameImage = Image.fromarray(frame)\n",
    "    plus_code_images = np.zeros((BATCH_SIZE, CHARACTER_HEIGHT, CHARACTER_WIDTH, 1))\n",
    "    pbar.update(1)\n",
    "    for i in range(0, NUM_CHARS):\n",
    "        left = LEFT_START + (i * CHARACTER_WIDTH_WITH_SPACE)\n",
    "        right = int(left) + CHARACTER_WIDTH\n",
    "        cropped = frameImage.crop((int(left), TOP, right, BOTTOM))\n",
    "        arr = np.asarray(cropped)\n",
    "        blur = cv2.GaussianBlur(arr, (3, 3), 0)\n",
    "        thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # Morph image to remove noise, and invert image\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        invert = 255 - opening\n",
    "\n",
    "        im_array = np.asarray(invert)\n",
    "        finished_image = Image.fromarray(im_array)\n",
    "\n",
    "        img_array = tf.keras.utils.img_to_array(finished_image)\n",
    "        plus_code_images[i] = img_array\n",
    "    model = submission_model\n",
    "    # Run the model over a batch of BATCH_SIZE images\n",
    "    result = model.predict(plus_code_images, batch_size=BATCH_SIZE, verbose=0, use_multiprocessing=True, workers=WORKER_COUNT)\n",
    "    plus_code_characters = []\n",
    "    for character in result:\n",
    "        predicted_character = VALID_LABELS[np.argmax(character)]\n",
    "        if predicted_character == \"NULL\":\n",
    "            predicted_character = \"?\"\n",
    "        plus_code_characters.append(predicted_character)\n",
    "    plus_code = \"\".join(plus_code_characters)\n",
    "    if olc.isValid(plus_code) and olc.isFull(plus_code):\n",
    "        latlng = olc.decode(plus_code).latlng()\n",
    "        \n",
    "        # Non-Descriptive Component.\n",
    "        # Because the model only has a 98% success rate, this code predicts what is and is not a valid waypoint for the flight.\n",
    "        # The if statement permits us to compare the last datapoint to the current datapoint. If the distance between the two points is not between MIN_REASONABLE_METERS_SEC and MAX_REASONABLE_METERS_SEC,\n",
    "        # as determined in Block 3, we can reasonably assume a character was misinterpreted by the model, but still yielded a valid plus-code. Thus, the point is discarded. \n",
    "        if len(found_coordinates) > 0:\n",
    "            calculated_distance = distance_meters(latlng, found_coordinates[-1])\n",
    "            # Increase our tolerance to distance jumps when we've lost more frames\n",
    "            seconds_since_last_successful_frame = (n - last_successful_frame_number) / VIDEO_FPS\n",
    "            if calculated_distance > MAX_REASONABLE_METERS_SEC * seconds_since_last_successful_frame:\n",
    "                invalid_coordinates.append(latlng)\n",
    "                #print(f\"{n/60} seconds: REJECTED code {plus_code} - distance={calculated_distance} meters.\")\n",
    "                continue\n",
    "            found_coordinates.append(latlng)\n",
    "            #print(f\"{n/60} seconds: accepted code {plus_code} - distance={calculated_distance} meters\")\n",
    "            last_successful_frame_number = n\n",
    "            total_distance = total_distance + calculated_distance\n",
    "            if calculated_distance / seconds_since_last_successful_frame > greatest_speed and calculated_distance < MAX_REASONABLE_METERS_SEC:\n",
    "                greatest_speed = calculated_distance / seconds_since_last_successful_frame\n",
    "            if calculated_distance < least_speed and calculated_distance > MIN_REASONABLE_METERS_SEC:\n",
    "                least_speed = calculated_distance\n",
    "        else:\n",
    "            found_coordinates.append(latlng)\n",
    "            #print(f\"{n/60} seconds: accepted code {plus_code}\")\n",
    "            last_successful_frame_number = n\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b96b26d-3814-45b0-bd2b-3c4bae834476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6: Display Block\n",
    "\n",
    "# Provides the 3 visuals.\n",
    "# 1. A pie chart, with the percentages of correct predictions, vs incorrect predictions.\n",
    "# 2. Average and Top Speeds for the flight.\n",
    "# 3. A map of the extracted data.\n",
    "\n",
    "average_speed = total_distance / (n / VIDEO_FPS)\n",
    "\n",
    "\n",
    "# Display the prediction pie ratio.\n",
    "labels = ['accepted prediction', 'rejected prediction']\n",
    "sizes = [len(found_coordinates), len(invalid_coordinates)]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "ax.axis('equal')\n",
    "ax.set_title('Estimated Correct Prediction Ratio')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Display average and max speed.\n",
    "\n",
    "data = {'Estimated Top Speed':greatest_speed, 'Average Speed':average_speed, 'Slowest Speed':least_speed}\n",
    "speeds = list(data.keys())\n",
    "values = list(data.values())\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "plt.bar(speeds, values, color ='maroon', width = 0.4)\n",
    "\n",
    "plt.xlabel(\"Speeds\")\n",
    "plt.ylabel(\"Meters per Second\")\n",
    "plt.title(\"Estimated Aircraft Velocity\")\n",
    "plt.show()\n",
    "\n",
    "# Show a map of the flight-path.\n",
    "m = Map(center = found_coordinates[0], \n",
    "        zoom = 11, \n",
    "        layout=Layout(width='60%', height='500px'))\n",
    "\n",
    "ant_path = AntPath(locations=found_coordinates, dash_array = [1, 10], delay=2000, color='#7590ba', pulse_color='#3f6fba' )\n",
    "m.add_layer(ant_path)\n",
    "display(m)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
